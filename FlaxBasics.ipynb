{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMEN4hBbmp27n2xcI0OZqcn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afairley/ColaboratoryNotebooks/blob/main/FlaxBasics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "il5tqgSIv9vR",
        "outputId": "20a55d75-af14-40d3-f81b-6ad7cc4eb668"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/79.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for flax (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade  -q pip jax jaxlib\n",
        "!pip install --upgrade -q git+https://github.com/google/flax.git\n",
        "import jax\n",
        "from typing import Any, Callable, Sequence\n",
        "from jax import random, numpy as jnp\n",
        "import flax\n",
        "from flax import linen as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Dense(features=5)\n",
        "key1, key2 = random.split(random.key(0))\n",
        "x = random.normal(key1, (10,))\n",
        "params = model.init(key2,x)\n",
        "jax.tree_util.tree_map(lambda x: x.shape,params)\n",
        "model.apply(params,x)\n",
        "\n",
        "n_samples = 20\n",
        "x_dim = 10\n",
        "y_dim = 5\n",
        "\n",
        "nextKey = random.key(0)\n",
        "k1, k2 = random.split(nextKey)\n",
        "W = random.normal(k1, (x_dim, y_dim))\n",
        "b = random.normal(k2,(y_dim,))\n",
        "\n",
        "true_params = flax.core.freeze({'params':{'bias': b, 'kernel': W}})\n",
        "key_sample, key_noise = random.split(k1)\n",
        "x_samples = random.normal(key_sample, (n_samples, x_dim))\n",
        "y_samples = jnp.dot(x_samples,W) + b + 0.1 *\\\n",
        " random.normal(key_noise,(n_samples, y_dim))\n",
        "print('x shape:', x_samples.shape, '; y shape:', y_samples.shape)\n",
        "print('x:', x_samples, '; y:', y_samples)"
      ],
      "metadata": {
        "id": "snFkF1n1wan7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@jax.jit\n",
        "def mean_squared_error(params, model, x_batched, y_batched):\n",
        "  def squared_error(x, y):\n",
        "    pred = model.apply(params, x)\n",
        "    return jnp.inner(y-pred, y-pred) / 2.0\n",
        "  return jnp.mean(jax.vmap(squared_error)(x_batched, y_batched), axis=0)"
      ],
      "metadata": {
        "id": "BDtCnavg1oLC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.3\n",
        "print('Loss for \"true\" W, b : ', mean_squared_error(true_params, model, x_samples, y_samples))\n",
        "loss_grad_fn = jax.value_and_grad(mean_squared_error)\n",
        "\n",
        "@jax.jit\n",
        "def update_params(params, learning_rate, grads):\n",
        "  params = jax.tree_util.tree_map(\n",
        "      lambda p, g: p - learning_rate * g, params, grads)\n",
        "  return params\n",
        "print(\"Reinitializing parameters\")\n",
        "params = model.init(key2,x)\n",
        "print(\"\\nParams\\n\", params, \"\\n\")\n",
        "for i in range(101):\n",
        "  loss_val, grads = loss_grad_fn(params, model, x_samples, y_samples)\n",
        "  params = update_params(params, learning_rate, grads)\n",
        "  if i % 10 == 0:\n",
        "    print(f'Loss step {i}:', loss_val)\n",
        "print(\"\\nParams\\n\", params, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_69ovfG2y5s",
        "outputId": "743c38f4-d76a-4154-b737-48a297f3be83"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for \"true\" W, b :  0.023639789\n",
            "\n",
            "Params\n",
            " {'params': {'kernel': Array([[ 2.35571519e-01, -1.71652585e-01, -4.45728786e-02,\n",
            "        -4.68043566e-01,  4.54595268e-01],\n",
            "       [-6.87736452e-01,  3.67835373e-01, -1.79262087e-01,\n",
            "         1.29276231e-01, -2.42580160e-01],\n",
            "       [ 2.02303097e-01, -2.49465615e-01,  2.74955630e-01,\n",
            "         4.73488361e-01, -1.98002517e-01],\n",
            "       [ 2.74478316e-01, -1.21369645e-01, -2.25361675e-01,\n",
            "        -4.78193641e-01, -9.63979885e-02],\n",
            "       [-6.19886033e-02, -1.72743499e-01,  2.96945305e-04,\n",
            "        -7.17593372e-01,  2.00894207e-01],\n",
            "       [-5.60321152e-01,  3.27208370e-01,  1.06281497e-01,\n",
            "         1.28758654e-01,  1.16973236e-01],\n",
            "       [ 1.82218999e-01,  1.11444063e-01, -1.62924141e-01,\n",
            "         3.24953087e-02, -1.67053342e-01],\n",
            "       [ 4.31294113e-01,  2.08004564e-01,  1.47714227e-01,\n",
            "        -8.51502866e-02, -1.26487061e-01],\n",
            "       [ 3.29497308e-01,  1.08470365e-01, -4.01340067e-01,\n",
            "         1.66956007e-01,  5.74723601e-01],\n",
            "       [-3.84744734e-01, -3.75315547e-01, -5.35782129e-02,\n",
            "        -2.51350880e-01, -4.78640765e-01]], dtype=float32), 'bias': Array([0., 0., 0., 0., 0.], dtype=float32)}} \n",
            "\n",
            "Loss step 0: 35.343876\n",
            "Loss step 10: 0.51434696\n",
            "Loss step 20: 0.11384159\n",
            "Loss step 30: 0.03932673\n",
            "Loss step 40: 0.019916212\n",
            "Loss step 50: 0.014209141\n",
            "Loss step 60: 0.012425661\n",
            "Loss step 70: 0.011850391\n",
            "Loss step 80: 0.011661777\n",
            "Loss step 90: 0.011599412\n",
            "Loss step 100: 0.0115787005\n",
            "\n",
            "Params\n",
            " {'params': {'bias': Array([-1.454525  , -2.0273795 ,  2.080245  ,  1.2191881 , -0.99601424],      dtype=float32), 'kernel': Array([[ 1.0111954 ,  0.19136539,  0.04576552, -0.9261725 ,  0.34677765],\n",
            "       [ 1.7307564 ,  0.9871511 ,  1.1651907 ,  1.1002556 , -0.10490108],\n",
            "       [-1.2007995 ,  0.28864196,  1.4177297 ,  0.12096123, -1.3133292 ],\n",
            "       [-1.194807  , -0.19073102,  0.03353279,  1.3159319 ,  0.08002902],\n",
            "       [ 0.13931455,  1.3698181 , -1.3176047 ,  0.5306085 , -2.2383754 ],\n",
            "       [ 0.5631883 ,  0.81093323,  0.31796947,  0.53365827,  0.9041459 ],\n",
            "       [-0.38095337,  1.7373483 ,  1.0776044 , -0.50716424,  0.92961043],\n",
            "       [ 0.9700136 , -1.3161405 ,  0.3362108 ,  0.80916613, -1.2023047 ],\n",
            "       [ 1.0198972 , -0.6196032 ,  1.0823339 , -1.8383787 , -0.45785123],\n",
            "       [-0.64433557,  0.45538047, -1.133502  , -0.68652624,  0.17053206]],      dtype=float32)}} \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optax\n",
        "tx = optax.adam(learning_rate=learning_rate)\n"
      ],
      "metadata": {
        "id": "XbTVD8ME66Wl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}