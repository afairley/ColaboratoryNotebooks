{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afairley/ColaboratoryNotebooks/blob/main/JaxBuildingMatrixAndTensorOperationsWithVMap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Jax Version Info\n",
        "\n"
      ],
      "metadata": {
        "id": "k_soeXix6keW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "jax.print_environment_info(return_string=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thtE4p77umZ8",
        "outputId": "82aa4b35-074e-4070-8fe8-c5cac03c60cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jax:    0.4.23\n",
            "jaxlib: 0.4.23\n",
            "numpy:  1.25.2\n",
            "python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "jax.devices (1 total, 1 local): [CpuDevice(id=0)]\n",
            "process_count: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#vmap examples\n"
      ],
      "metadata": {
        "id": "AGwuGC2UxRU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"from DocString and other permutation variants\n",
        "Still don't have a solid operational definition of the exact behavior\n",
        "of vmap yet, but I think this is most of the basic meaningful permutations.\n",
        "There are quite a few other permutations that can be done even restricting\n",
        "ourselves to a \"pair\" tuple with no tree structure for in_axes.\n",
        "\n",
        "It basically looks to work along the lines you'd expect if you've implemented\n",
        "this sort of code before. Theoretically refactoring all the code in jax that\n",
        "does something along the lines of turning user provided list and tuple pytrees\n",
        "into tuple pytrees and getting all the code backing vmap into a single module\n",
        "might provide some efficiency gains depending on how actual python's JIT\n",
        "handles function calls across many modules and back and forth over the\n",
        "jaxlib/jax boundry. It has presumably been looked at internally.\n",
        "\n",
        "I'm not really sure if I want to proceed by writing a pretty printer for matrices and tensors and their various products or unrolling all the code.\n",
        "Most likely I'm going to do both, although I actually want to read through\n",
        "the haiku and XLA source at present as well. VMap appears to call all the\n",
        "way down into XLA, so I can probably scratch that itch while staying\n",
        "\"on task\" as it were.\n",
        "\n",
        "Perhaps there is some other wasy I can stash this text here in this markdown instance, the following effort based on advice from the hoi polloi doens't seem to work.( https://stackoverflow.com/questions/4823468/comments-in-markdown )\n",
        "[//]: # It would appear that while tree_map is perfectly happy to map over\n",
        "[//]: # tuple trees vmap does not handle them unless they are upgraded to\n",
        "[//]: # jnp.array\n",
        "[//]: # #mm(expansionMatrix,reductionMatrix) #appears to throw a shape error \"\"\""
      ],
      "metadata": {
        "id": "c0502Bm-6_gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.numpy as jnp\n",
        "import jax.tree_util as tree_util\n",
        "from jax import vmap\n",
        "\n",
        "\n",
        "vv = lambda x, y: jnp.vdot(x, y)  #  ([a], [a]) -> []\n",
        "mv = vmap(vv, (0, None), 0)      #  ([b,a], [a]) -> [b]      (b is the mapped axis)\n",
        "mm = vmap(mv, (None, 1), 1)      #  ([b,a], [a,c]) -> [b,c]  (c is the mapped axis)\n",
        "\n",
        "mv1 = vmap(vv, (0, 0), 0)   #  ([b,a], [b,a]) -> [b]        (b is the mapped axis)\n",
        "mv2 = vmap(vv, (0, 1), 0)   #  ([b,a], [a,b]) -> [b]        (b is the mapped axis)\n",
        "\n",
        "#this thing is actuall some sort of tensor product and not a matrix product at\n",
        "#all\n",
        "tp1 = vmap(mv2, (1, 1), 0)  #  mm2 originally\n",
        "                            #([b,c,a], [a,c,b]) -> [c,b]  (c is the mapped axis)\n",
        "\n",
        "vm = vmap(vv, (None, 0), 0)      #  ([a], [a,b]) -> [a]\n",
        "mm3 = vmap(vm, (1, None), 1)     #so this looks like the reversed matrix conventions\n",
        "                                 #as far as I recall from yesterday\n",
        "                                 #straight application of pattern matching\n",
        "                                 #and inversion of indices would suggest that it does\n",
        "                                 #  ([a,b], [b,c]) -> [c,b]\n",
        "\n",
        "#other variants\n",
        "vm2 = vmap(vv, (None, 1), 0)\n",
        "mm4 = vmap(vm, (1, None), 1)\n",
        "\n",
        "#switching the tuple in this way inverts the order of matrix multiplication\n",
        "#constituent operations\n",
        "vmapped_dot = vmap(vv, (1, None), 0)\n",
        "vmapped_vmapped_dot = vmap(vmapped_dot, (None, 0), 1)\n",
        "\n",
        "\n",
        "vmapped_dot2 = vmap(vv, (0, None), 0)\n",
        "vmapped_vmapped_dot2 = vmap(vmapped_dot2, (None, 1), 1)"
      ],
      "metadata": {
        "id": "GsJh1Lg4u7ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Matrices"
      ],
      "metadata": {
        "id": "rGyCOvgYxhQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "identityMatrix = jnp.array(((1,0,0),\n",
        "                  (0,1,0),\n",
        "                  (0,0,1)))\n",
        "permuteABMatrix = jnp.array(((0,1,0),\n",
        "                  (1,0,0),\n",
        "                  (0,0,1)))\n",
        "permuteBCMatrix = jnp.array(((1,0,0),\n",
        "                  (0,0,1),\n",
        "                  (0,1,0)))\n",
        "oneRowVector = jnp.array((1,1,1))\n",
        "oneColumnVector = jnp.array(((1),\n",
        "                             (1),\n",
        "                             (1)))\n",
        "columnMatrix = jnp.array(((1,0,0),\n",
        "                  (2,0,0),\n",
        "                  (3,0,0)))\n",
        "rowMatrix = jnp.array(((1,4,9),\n",
        "                  (0,0,0),\n",
        "                  (0,0,0)))\n",
        "columnMatrix2 = jnp.array(((0,0,1),\n",
        "                  (0,0,2),\n",
        "                  (0,0,3)))\n",
        "rowMatrix2 = jnp.array(((0,0,0),\n",
        "                  (0,0,0),\n",
        "                  (1,4,9)))\n",
        "\n",
        "#expansionMatrix = map( lambda x: map( lambda y: y *2, x) *2 , identityMatrix)\n",
        "#You can no longer do the above.\n",
        "def right_multiply_matrix_by_scalar(matrix, scalar):\n",
        "  return tree_util.tree_map(lambda x : x * scalar, matrix)\n",
        "expansionMatrix = right_multiply_matrix_by_scalar(identityMatrix, 2)\n",
        "reductionMatrix = right_multiply_matrix_by_scalar(identityMatrix, 0.5)\n",
        "\n"
      ],
      "metadata": {
        "id": "pQLBlDDVv3Kj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Identity Matrix I:\\n\" , identityMatrix)\n",
        "print(\"Permutation Matrix P_AB:\\n\" , permuteABMatrix)\n",
        "print(\"Permutation Matrix P_BC:\\n\" , permuteBCMatrix)\n",
        "print(\"RowVector v1:\\n\" , oneRowVector)\n",
        "print(\"Column Vector vT1:\\n\" , oneColumnVector)\n",
        "print(\"Expansion Matrix E:\\n\" , expansionMatrix)\n",
        "print(\"Reduction Matrix R:\\n\" , reductionMatrix)\n",
        "print(\"Column Matrix C:\\n\" , columnMatrix)\n",
        "print(\"Row Matrix R:\\n\" , rowMatrix)\n",
        "print(\"Column Matrix C2:\\n\" , columnMatrix2)\n",
        "print(\"Row Matrix R2:\\n\" , rowMatrix2)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UP6Xv5Vs3nYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Applications of various \"Products\"\n"
      ],
      "metadata": {
        "id": "8zk6Muu02rPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Without writing a pretty printer for printing multiple matrices in shared console real estate,\n",
        " following the following is more cognitive overhead than is sensible for reasoning.\n",
        "  Math notation is handy for a reason.\n",
        "   I will probably write a narrowly delimited matrix pretty printer.\n",
        "   Something taking 3 at most maybe 4x4 matrices ought to be reasonably straight\n",
        "    forward and presumably has been written dozens of times. Maybe I can find\n",
        "    one if I look around a bit.\"\"\""
      ],
      "metadata": {
        "id": "NAZv39lA7Hm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"mm product E * R:\\n\",\n",
        "    mm(expansionMatrix,reductionMatrix))\n",
        "print(\"mm product C * R:\\n\",\n",
        "    mm(columnMatrix,rowMatrix))\n",
        "print(\"mm product R * C:\\n\",\n",
        "    mm(rowMatrix,columnMatrix))\n",
        "print(\"mm product C2 * R2:\\n\",\n",
        "    mm(columnMatrix2,rowMatrix2))\n",
        "print(\"mm product R2 * C2:\\n\",\n",
        "    mm(rowMatrix2,columnMatrix2))\n",
        "\n"
      ],
      "metadata": {
        "id": "-u3IbtJK3jIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"vm product rV1 * I:\\n\",\n",
        "    vm(oneRowVector,identityMatrix))\n",
        "print(\"vm product I * E:\\n\",\n",
        "    vm(oneRowVector,expansionMatrix))\n",
        "\n",
        "print(\"vm2 product rV1 * I:\\n\",\n",
        "    vm2(oneRowVector,identityMatrix))\n",
        "print(\"vm2 product I * E:\\n\",\n",
        "    vm2(oneRowVector,expansionMatrix))"
      ],
      "metadata": {
        "id": "3WrPLsks6FHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"mm3 product E * R:\\n\",\n",
        "    mm3(expansionMatrix,reductionMatrix))\n",
        "print(\"mm3 product C * R:\\n\",\n",
        "    mm3(columnMatrix,rowMatrix))\n",
        "print(\"mm3 product R * C:\\n\",\n",
        "    mm3(rowMatrix,columnMatrix))\n",
        "print(\"mm3 product C2 * R2:\\n\",\n",
        "    mm3(columnMatrix2,rowMatrix2))\n",
        "print(\"mm3 product R2 * C2:\\n\",\n",
        "    mm3(rowMatrix2,columnMatrix2))"
      ],
      "metadata": {
        "id": "YIq93If65UGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"vmapped_vmapped_dot product E * R:\\n\",\n",
        "    vmapped_vmapped_dot(expansionMatrix,reductionMatrix))\n",
        "print(\"vmapped_vmapped_dot product C * R:\\n\",\n",
        "    vmapped_vmapped_dot(columnMatrix,rowMatrix))\n",
        "print(\"vmapped_vmapped_dot product R * C:\\n\",\n",
        "    vmapped_vmapped_dot(rowMatrix,columnMatrix))\n",
        "print(\"vmapped_vmapped_dot product C2 * R2:\\n\",\n",
        "    vmapped_vmapped_dot(columnMatrix2,rowMatrix2))\n",
        "print(\"vmapped_vmapped_dot product R2 * C2:\\n\",\n",
        "    vmapped_vmapped_dot(rowMatrix2,columnMatrix2))"
      ],
      "metadata": {
        "id": "CYXxIEv__28I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"mv1 product E * E:\\n\",\n",
        "          (mv1(expansionMatrix,expansionMatrix)))\n",
        "print(\"mv1 product C * R:\\n\",\n",
        "    mv1(columnMatrix,rowMatrix))\n",
        "print(\"mv1 product R * C:\\n\",\n",
        "    mv1(rowMatrix,columnMatrix))"
      ],
      "metadata": {
        "id": "wR0Zi3ed4jCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Actual Proper \"Tensors\"\n"
      ],
      "metadata": {
        "id": "r8zr7Lu7xxSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"(even though there's nothing here about covariant or contravariant indices in so far as I can tell which I'm pretty sure is important for proper tensors)\n",
        "\n",
        "Also I'm pretty sure the abuse of \"rank\" by tensor oriented people to mean\n",
        "dimension is the origin of the abuse of \"rank\" to mean dimension instead of meaning the de facto dimension of a potentially higher dimension'd matrix as\n",
        "modern mathematicians mean rank.\"\"\""
      ],
      "metadata": {
        "id": "_Ve1wXY07eGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rank3DiagonalUnityVectorTensor = jnp.array(\n",
        "                  (\n",
        "                    (\n",
        "                    ((1,0,0),\n",
        "                    (0,0,0),\n",
        "                    (0,0,0))\n",
        "                    ,\n",
        "                    ((0,0,0),\n",
        "                    (0,0,0),\n",
        "                    (0,0,0))\n",
        "                    ,\n",
        "                    ((0,0,0),\n",
        "                    (0,0,0),\n",
        "                    (0,0,0))\n",
        "                    ),\n",
        "                    (\n",
        "                    ((0,0,0),\n",
        "                    (0,0,0),\n",
        "                    (0,0,0))\n",
        "                    ,\n",
        "                    ((0,0,0),\n",
        "                    (0,1,0),\n",
        "                    (0,0,0))\n",
        "                    ,\n",
        "                    ((0,0,0),\n",
        "                    (0,0,0),\n",
        "                    (0,0,0))\n",
        "                    ),\n",
        "                    (\n",
        "                    ((0,0,0),\n",
        "                    (0,0,0),\n",
        "                    (0,0,0))\n",
        "                    ,\n",
        "                    ((0,0,0),\n",
        "                    (0,0,0),\n",
        "                    (0,0,0))\n",
        "                    ,\n",
        "                    ((0,0,0),\n",
        "                    (0,0,0),\n",
        "                    (0,0,1))\n",
        "                    )\n",
        "))\n",
        "print(\"tp1/\\\"mm2\\\" product sillyTensor * sillyTensor:\\n\",\n",
        "    tp1(rank3DiagonalUnityVectorTensor,rank3DiagonalUnityVectorTensor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5R77ymX21QQ",
        "outputId": "867a830e-37c2-4f71-cfc2-fa7222add93e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tp1/\"mm2\" product sillyTensor * sillyTensor:\n",
            " [[1 0 0]\n",
            " [0 1 0]\n",
            " [0 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Irrelevance"
      ],
      "metadata": {
        "id": "OGkfeg2_8Gbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## How deep does section folding work\n",
        "# Not deep enough :D\n",
        "\"\"\"\n",
        "Vmap__Source = \"https://github.com/google/jax/blob/main/jax/_src/api.py#L1061\"\n",
        "\n",
        "tree_flatten__Source = '''There are in fact numerous definitions of tree_flatten. Looking at imports it is presumably\n",
        "\n",
        "https://github.com/google/jax/blob/main/jax/_src/tree_util.py#L71\n",
        "\n",
        "https://github.com/google/jax/blob/main/jax/_src/lib/__init__.py#L93\n",
        "Which is a layer of indirection around\n",
        "jaxlib.xla_client._xla.pytree\n",
        "which is somewhere in the C++ code\n",
        "\n",
        "4.29.2024 Looking at help(jaxlib.xla_client) I see that it is from a file\n",
        "installed as /usr/local/lib/python3.10/dist-packages/jaxlib/xla_client.py\n",
        "which is in fact presumably some sort of file autogenerated during the build\n",
        "process of jaxlib. There is some snarky commentary presumably from a googler at\n",
        "https://stackoverflow.com/questions/66257662/what-exactly-is-xla-client-in-the-jax-library\n",
        "which points to some outdated bazel files from the tensorflow project\n",
        "(i.e. said files no longer exist in the tensorflow project in the locations\n",
        "pointed to snarkily)\n",
        "\n",
        "Looking at {JAX_DIR}/jaxlib/BUILD I see\n",
        "\n",
        "...\n",
        "symlink_files(\n",
        "    name = \"xla_client\",\n",
        "    srcs = [\"@xla//xla/python:xla_client\"],\n",
        "    dst = \".\",\n",
        "    flatten = True,\n",
        ")\n",
        "\n",
        "symlink_files(\n",
        "    name = \"xla_extension\",\n",
        "    srcs = if_windows(\n",
        "        [\"@xla//xla/python:xla_extension.pyd\"],\n",
        "        [\"@xla//xla/python:xla_extension.so\"],\n",
        "    ),\n",
        "    dst = \".\",\n",
        "    flatten = True,\n",
        ")\n",
        "...\n",
        "which looks like the kind of thing the stackoverflow commenter is talking about\n",
        "Looking around the xla source for xla_client I first stumbled upon pytree.cc\n",
        "which looks like it has the code I've been looking for at\n",
        "https://github.com/openxla/xla/blob/main/xla/python/pytree.cc#L1264\n",
        "https://github.com/openxla/xla/blob/main/xla/python/pytree.cc#L296\n",
        "'''\n",
        "lu.wrap_init__Source = \"https://github.com/google/jax/blob/main/jax/_src/linear_util.py#L262\"\n",
        "\n",
        "batching.flatten_fun_for_vmap__Source = https://github.com/google/jax/blob/main/jax/_src/interpreters/batching.py#L304\n",
        "\n",
        "flatten_axes__Source:https://github.com/google/jax/blob/main/jax/_src/api_util.py#L404\n",
        "\n",
        "tree_unflatten__Source: Similar story to tree_flatten\n",
        "\n",
        "https://github.com/google/jax/blob/main/jax/_src/tree_util.py#L107\n",
        "\n",
        "cast__Source:(imported from python's typing module)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "DDmnfMzj9bp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Reading the docstring for vmap again now, an interesting,not necessarily\n",
        "achievable exercise might be to write some sort of meaningful vector triple\n",
        "product.  The cross product isn't it though I was thinking that.\n",
        "There's the \"scalar\" triple product and the \"vector\" triple products.\n",
        "https://en.wikipedia.org/wiki/Triple_product\n",
        "I think theoretically you might be able to write the vector triple product\n",
        "with vmap.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "06qEzsF-_Ns9",
        "outputId": "f4c0a498-d268-441b-c464-d34263362a9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Reading the docstring for vmap again now, an interesting,not necessarily \\nachievable exercise might be to write some sort of meaningful vector triple \\nproduct.  The cross product isn\\'t it though I was thinking that.\\nThere\\'s the \"scalar\" triple product and the \"vector\" triple products.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Irrelevance"
      ],
      "metadata": {
        "id": "Qh7cW-9N-DQW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xr2dUi8ktplY"
      },
      "outputs": [],
      "source": [
        "#Doing this isn't actually needed as colab instances\n",
        "#come with jax installed(unless you want to browse source in colab)\n",
        "#the github browser has gotten good enough to read in some as long as you have\n",
        "#something like colab to play around in.\n",
        "projects = [\n",
        "    (\"jax\",\"https://github.com/google/jax\")]\n",
        "JAX_DIR = f\"/content/{projects[0][0]}\"\n",
        "for project, repo in projects:\n",
        "  !rm -rf ./{project}\n",
        "  !git clone {repo}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Doing this isn't actually needed as colab instances\n",
        "#come with jax installed\n",
        "!pip install jaxlib\n",
        "!cd {JAX_DIR} && pip install -e .\n"
      ],
      "metadata": {
        "id": "5EItG6dNt449"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}